{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score,train_test_split,GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,precision_score,recall_score,precision_recall_fscore_support,classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The US Supreme Court Monday refused to hear an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Police are still searching for an East Europea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Two sheep thieves in NWest court Molaole Monts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A teenager and her younger brother were killed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  The US Supreme Court Monday refused to hear an...\n",
       "1  Police are still searching for an East Europea...\n",
       "2  Two sheep thieves in NWest court Molaole Monts...\n",
       "3  A teenager and her younger brother were killed..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.iloc[:,-1:]\n",
    "\n",
    "test.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the extracted news as df\n",
    "data = pd.read_csv('../data/extracted_data.csv').drop('Unnamed: 0', axis=1)\n",
    "data.columns = ['url','section','location','headline','text','label']\n",
    "\n",
    "\n",
    "# getting the extracted test news as df\n",
    "data_test = pd.read_csv('../data/extracted_test_data.csv').drop('Unnamed: 0', axis=1)\n",
    "data_test.columns = ['url','section','location','headline','text','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging headline and content as another column and create another dataframe with jusst text and label.\n",
    "df = pd.DataFrame([data.headline+\". \"+data.text,data.label]).transpose()\n",
    "df.columns = ['text','label']\n",
    "\n",
    "\n",
    "# merging headline and content as another column and create another dataframe with jusst text and label.\n",
    "df_test = pd.DataFrame([data_test.headline+\". \"+data_test.text,data_test.label]).transpose()\n",
    "df_test.columns = ['text','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing function \n",
    "    # split an article into sentences\n",
    "        # go to each sentence and split it to words\n",
    "            # if this word  is not in stopwords or other common words I've decided\n",
    "                #AND\n",
    "                   # if its alphabetic (getting rid of puctuation and numbers)\n",
    "                        #AND\n",
    "                            # if len of the word is greater than 2\n",
    "                            \n",
    "                            # lemmatize and lowercase the the word\n",
    "                            \n",
    "                            # return the cleaned article\n",
    "def preprocess(news):\n",
    "    l = WordNetLemmatizer()\n",
    "    sentences = news.split(\".\")\n",
    "    return \" \".join([l.lemmatize(word.lower()) for sentence in sentences for word in sentence.split() if word not in stopwords if word.isalpha() if len(word)> 2 if word.lower() not in [\"said\",\"the\",\"first\",\"also\",\"would\",\"one\",\"two\",\"they\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>reader mail ruling alimony supreme court exten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>niqaab elephant say judge person may give evid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>grandparent honoured staff student global publ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>fisherman call strike country boat fisherman l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  reader mail ruling alimony supreme court exten...     0\n",
       "1  niqaab elephant say judge person may give evid...     0\n",
       "2  grandparent honoured staff student global publ...     0\n",
       "3  fisherman call strike country boat fisherman l...     1"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text'] =  test['text'].map(preprocess) \n",
    "\n",
    "# apply preprocess() function to each article\n",
    "df['text'] = df['text'].map(preprocess)\n",
    "\n",
    "\n",
    "\n",
    "# apply preprocess() function to each article\n",
    "df_test['text'] = df_test['text'].map(preprocess)\n",
    "\n",
    "df = pd.concat([df,df_test]).reset_index().drop('index',axis=1)\n",
    "\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting protest and not_protest news\n",
    "protest_news = df[df.label == 1].text\n",
    "not_protest_news = df[df.label == 0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayes theorem. \n",
    "    # finding the probability for being protest or not protest for an article which includes given word\n",
    "def word_affect(word):\n",
    "    number_of_occurance_in_protest_list = 0\n",
    "    for article in protest_news:\n",
    "        for w in article.split():\n",
    "            if w == word:\n",
    "                number_of_occurance_in_protest_list +=1\n",
    "                break \n",
    "                \n",
    "    number_of_occurance_in_not_protest_list = 0\n",
    "    for article in not_protest_news:\n",
    "        for w in article.split():\n",
    "            if w == word:\n",
    "                number_of_occurance_in_not_protest_list +=1\n",
    "                break       \n",
    "\n",
    "    \n",
    "    pi1 = len(protest_news)/(len(protest_news)+len(not_protest_news))\n",
    "    pi2 = len(not_protest_news)/(len(protest_news)+len(not_protest_news))\n",
    "    fkx = number_of_occurance_in_protest_list/len(protest_news)\n",
    "    fkx_ = number_of_occurance_in_not_protest_list/len(not_protest_news)\n",
    "    prob = (pi1*fkx)/((pi1*fkx)+(pi2*fkx_))\n",
    "    \n",
    "    \n",
    "    #returns (probability of protest, probability of not protest)\n",
    "        # this is might seem counterintutitive with word freqs but we must remember the ratio of news\n",
    "    return(prob,1-prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.801980198019802, 0.19801980198019797)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_affect(\"protest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = df.text\n",
    "labels = df.label\n",
    "\n",
    "train_articles,test_articles,train_label,test_label = train_test_split(articles,labels,test_size = 0.3, shuffle=True)\n",
    "test_art =  test.text\n",
    "#test_labels = df_test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df= 5, ngram_range=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_articles = vectorizer.fit_transform(train_articles).toarray().astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(541, 2249)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 1742)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protest_target_words = []\n",
    "non_protest_target_words = []\n",
    "for word in list(vectorizer.vocabulary_.keys()):\n",
    "    if word_affect(word)[0]-word_affect(word)[1] > 0.4:\n",
    "        protest_target_words.append((word,(word_affect(word)[0],word_affect(word)[1])))\n",
    "        \n",
    "    elif word_affect(word)[1]-word_affect(word)[0] > 0.3 :\n",
    "        non_protest_target_words.append((word,(word_affect(word)[0],word_affect(word)[1])))\n",
    "        \n",
    "        \n",
    "len(protest_target_words),len(non_protest_target_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('policeman', (0.7333333333333334, 0.2666666666666666)),\n",
       " ('staged', (0.8275862068965517, 0.1724137931034483)),\n",
       " ('protest', (0.801980198019802, 0.19801980198019797)),\n",
       " ('demonstration', (0.9259259259259258, 0.07407407407407418)),\n",
       " ('protester', (0.9375, 0.0625)),\n",
       " ('mlas', (0.7999999999999999, 0.20000000000000007)),\n",
       " ('dharna', (0.9, 0.09999999999999998)),\n",
       " ('collectorate', (0.7692307692307693, 0.23076923076923073)),\n",
       " ('agitation', (0.7272727272727272, 0.2727272727272728)),\n",
       " ('activist', (0.7954545454545454, 0.20454545454545459)),\n",
       " ('mob', (0.75, 0.25)),\n",
       " ('rally', (0.8095238095238095, 0.19047619047619047)),\n",
       " ('demanding', (0.7580645161290324, 0.24193548387096764)),\n",
       " ('tense', (0.875, 0.125)),\n",
       " ('banner', (0.7777777777777777, 0.22222222222222232)),\n",
       " ('custody', (0.7272727272727273, 0.2727272727272727)),\n",
       " ('attack', (0.7222222222222223, 0.2777777777777777)),\n",
       " ('cbi', (0.7777777777777777, 0.22222222222222232)),\n",
       " ('suspect', (0.9, 0.09999999999999998)),\n",
       " ('communal', (0.7999999999999999, 0.20000000000000007)),\n",
       " ('riot', (0.8333333333333333, 0.16666666666666674)),\n",
       " ('stir', (0.75, 0.25)),\n",
       " ('memorandum', (0.7222222222222223, 0.2777777777777777)),\n",
       " ('protesting', (0.8, 0.19999999999999996)),\n",
       " ('violence', (0.7307692307692307, 0.2692307692307693)),\n",
       " ('tirupur', (0.7142857142857143, 0.2857142857142857)),\n",
       " ('arrest', (0.75, 0.25)),\n",
       " ('boycott', (0.7142857142857143, 0.2857142857142857)),\n",
       " ('cadre', (0.7692307692307693, 0.23076923076923073)),\n",
       " ('assault', (0.888888888888889, 0.11111111111111105)),\n",
       " ('atrocity', (1.0, 0.0)),\n",
       " ('clash', (0.75, 0.25)),\n",
       " ('excess', (0.8333333333333333, 0.16666666666666674)),\n",
       " ('protestors', (1.0, 0.0)),\n",
       " ('hike', (0.7692307692307693, 0.23076923076923073)),\n",
       " ('deployed', (0.7142857142857143, 0.2857142857142857)),\n",
       " ('killed', (0.7241379310344828, 0.27586206896551724)),\n",
       " ('incident', (0.7142857142857143, 0.2857142857142857)),\n",
       " ('protested', (0.75, 0.25)),\n",
       " ('injured', (0.8, 0.19999999999999996)),\n",
       " ('attacked', (0.8461538461538461, 0.15384615384615385)),\n",
       " ('violent', (0.875, 0.125)),\n",
       " ('agitator', (1.0, 0.0)),\n",
       " ('detained', (1.0, 0.0)),\n",
       " ('kill', (0.7142857142857143, 0.2857142857142857)),\n",
       " ('bandh', (0.9166666666666667, 0.08333333333333326)),\n",
       " ('sangh', (0.7142857142857143, 0.2857142857142857)),\n",
       " ('wage', (0.8181818181818181, 0.18181818181818188)),\n",
       " ('erupted', (0.7999999999999999, 0.20000000000000007)),\n",
       " ('prevailed', (0.7777777777777777, 0.22222222222222232)),\n",
       " ('witnessed', (0.8571428571428571, 0.1428571428571429)),\n",
       " ('alleging', (0.7999999999999999, 0.20000000000000007)),\n",
       " ('gulbarga', (0.7142857142857143, 0.2857142857142857)),\n",
       " ('blocked', (0.7142857142857143, 0.2857142857142857)),\n",
       " ('procession', (0.75, 0.25)),\n",
       " ('suspected', (0.8333333333333333, 0.16666666666666674))]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protest_target_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for article in test_articles:\n",
    "    if len(set(article.split()))-len(set(article.split())-set([i[0] for i in protest_target_words]))>1:\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93       169\n",
      "           1       0.80      0.83      0.82        64\n",
      "\n",
      "    accuracy                           0.90       233\n",
      "   macro avg       0.87      0.88      0.87       233\n",
      "weighted avg       0.90      0.90      0.90       233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(results,list(test_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[156,  13],\n",
       "       [ 11,  53]], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(results,list(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS = [i[0] for i in protest_target_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors=[]\n",
    "for article in train_articles:\n",
    "    article_words = list(set(article.split()))\n",
    "    \n",
    "    article_vector = []\n",
    "    for word in WORDS:\n",
    "        if word in article_words:\n",
    "            article_vector.append(1)\n",
    "        else:\n",
    "            article_vector.append(0)\n",
    "    vectors.append(article_vector)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_vectors=[]\n",
    "for article in test_articles:\n",
    "    article_words = list(set(article.split()))\n",
    "    \n",
    "    article_vector = []\n",
    "    for word in WORDS:\n",
    "        if word in article_words:\n",
    "            article_vector.append(1)\n",
    "        else:\n",
    "            article_vector.append(0)\n",
    "    t_vectors.append(article_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91       177\n",
      "           1       0.70      0.82      0.75        56\n",
      "\n",
      "    accuracy                           0.87       233\n",
      "   macro avg       0.82      0.85      0.83       233\n",
      "weighted avg       0.88      0.87      0.87       233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(SVC().fit(pd.DataFrame(vectors),list(train_label)).predict(pd.DataFrame(t_vectors)),list(test_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8466181382732735"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model = SVC()\n",
    "\n",
    "hyperparameters= dict(kernel=[\"linear\", \"poly\",\"sigmoid\"],\n",
    "                      C=np.logspace(0, 4, 5),\n",
    "                      gamma=('scale', 'auto'))\n",
    "                      #class_weight=[{1:1,0:1},{1:2,0:1},{1:3,0:1},{1:3,0:0.5},{1:4,0:0.5},{1:4,0:1}])\n",
    "\n",
    "svc_grid = GridSearchCV(svc_model, hyperparameters, cv=5,scoring='f1_macro')\n",
    "\n",
    "best_svc = svc_grid.fit(pd.DataFrame(vectors),list(train_label))\n",
    "\n",
    "best_svc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10.0, 'gamma': 'scale', 'kernel': 'linear'}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.83      0.89       190\n",
      "           1       0.52      0.79      0.62        43\n",
      "\n",
      "    accuracy                           0.82       233\n",
      "   macro avg       0.73      0.81      0.75       233\n",
      "weighted avg       0.87      0.82      0.84       233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(best_svc.predict(pd.DataFrame(t_vectors)),list(test_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatihbeyhan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\fatihbeyhan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\fatihbeyhan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\fatihbeyhan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\fatihbeyhan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\fatihbeyhan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8542121887500106"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "\n",
    "\n",
    "hyperparameters = dict(C= np.logspace(0, 4, 5))\n",
    "                       #class_weight = [{1:1,0:1},{1:2,0:1},{1:3,0:1},{1:3,0:0.5},{1:4,0:0.5},{1:4,0:1}])\n",
    "\n",
    "logistic_grid = GridSearchCV(logistic_model, hyperparameters, cv=3,scoring='f1_macro')\n",
    "\n",
    "best_logistic = logistic_grid.fit(pd.DataFrame(vectors),list(train_label))\n",
    "\n",
    "best_logistic.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10.0}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_logistic.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90       190\n",
      "           1       0.55      0.84      0.66        43\n",
      "\n",
      "    accuracy                           0.84       233\n",
      "   macro avg       0.75      0.84      0.78       233\n",
      "weighted avg       0.88      0.84      0.85       233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(best_logistic.predict(pd.DataFrame(t_vectors)),list(test_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.tensor as tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(pd.DataFrame(vectors).to_numpy()).float()\n",
    "y_train = torch.from_numpy(np.array(list(train_label))).float().view(len(train_label),1)\n",
    "\n",
    "x_test = torch.from_numpy(pd.DataFrame(t_vectors).to_numpy()).float()\n",
    "y_test = torch.from_numpy(np.array(list(test_label))).float().view(len(test_label),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([541, 56]), torch.Size([541, 1]), torch.float32, torch.float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape,x_train.dtype,y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "shuffled_idx = [i for i in range(len(y_train))]\n",
    "random.shuffle(shuffled_idx)\n",
    "\n",
    "batch_size = 581\n",
    "\n",
    "batches = []\n",
    "for i in range(0,len(y_train),batch_size):\n",
    "\n",
    "    indices= [shuffled_idx[i:i+batch_size]]\n",
    "\n",
    "    batches.append([x_train[indices],y_train[indices]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([541, 56]), torch.Size([541, 1]))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[0][0].shape,batches[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProtestClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ProtestClassifier,self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(x_train.shape[1],64)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.layer2 = nn.Linear(64,1)\n",
    "        self.drop2 = nn.Dropout(p=0.2)\n",
    "        self.layer3= nn.Linear(64,32)\n",
    "        self.drop3 = nn.Dropout(p=0.2)\n",
    "        self.layer4= nn.Linear(32,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "    def predict(self,x):\n",
    "        pred = self.forward(x)\n",
    "        ans = []\n",
    "        for t in pred:\n",
    "            if t[0]>0.500001:\n",
    "                ans.append(1)\n",
    "            else:\n",
    "                ans.append(0)\n",
    "        return torch.tensor(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the model\n",
    "model = ProtestClassifier()\n",
    "#Define loss criterion\n",
    "criterion = nn.BCELoss()\n",
    "#Define the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 \t Training Loss: 0.5047 Eval Loss: 0.5563\n",
      "140 \t Training Loss: 0.3978 Eval Loss: 0.475\n",
      "210 \t Training Loss: 0.3053 Eval Loss: 0.4061\n",
      "280 \t Training Loss: 0.2635 Eval Loss: 0.3672\n",
      "350 \t Training Loss: 0.2427 Eval Loss: 0.3573\n",
      "420 \t Training Loss: 0.2286 Eval Loss: 0.3553\n",
      "490 \t Training Loss: 0.2258 Eval Loss: 0.3411\n",
      "560 \t Training Loss: 0.2134 Eval Loss: 0.3482\n",
      "\n",
      "\n",
      "Training Loss: 0.2079 Eval Loss: 0.3468\n"
     ]
    }
   ],
   "source": [
    "#Number of epochs\n",
    "epochs = 630\n",
    "#List to store losses\n",
    "trn_losses = []\n",
    "eval_losses = []\n",
    "for i in range(1,epochs):\n",
    "    for batch in batches:\n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "        \n",
    "        y_pred = model.forward(x)\n",
    "        loss = criterion(y_pred,y)    \n",
    "\n",
    "      \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i % 70 == 0:\n",
    "        evalloss = criterion(model.forward(x_test),y_test)\n",
    "        print(i,'\\t',\"Training Loss:\",round(loss.item(),4),\"Eval Loss:\",round(evalloss.item(),4))\n",
    "        trn_losses.append(round(loss.item(),4))\n",
    "        eval_losses.append(round(evalloss.item(),4))\n",
    "\n",
    "evalloss = criterion(model.forward(x_test),y_test)\n",
    "print(\"\\n\\nTraining Loss:\",round(loss.item(),4),\"Eval Loss:\",round(evalloss.item(),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91       193\n",
      "           1       0.56      0.93      0.70        40\n",
      "\n",
      "    accuracy                           0.86       233\n",
      "   macro avg       0.77      0.89      0.80       233\n",
      "weighted avg       0.91      0.86      0.87       233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(model.predict(x_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
