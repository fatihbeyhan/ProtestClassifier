{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score,train_test_split,GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix,accuracy_score,f1_score,precision_score,recall_score,precision_recall_fscore_support,classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import json\n",
    "%matplotlib inline\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL1 = 'C_logistic_model.sav'\n",
    "MODEL2 = 'C_svc_model.sav'\n",
    "MODEL3 = 'C_knn_model.sav'\n",
    "logistic_model = pickle.load(open(\"../models/\"+MODEL1, 'rb'))\n",
    "svc_model = pickle.load(open(\"../models/\"+MODEL2, 'rb'))\n",
    "knn_model = pickle.load(open(\"../models/\"+MODEL3, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = '../data/Sabinet_R_no_labels.json'\n",
    "    \n",
    "with open(json_file, 'r') as handle:\n",
    "    json_data = [json.loads(line) for line in handle]\n",
    "    \n",
    "json_text = [i['text'] for i in json_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.DataFrame(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(json_text,columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(news):\n",
    "    l = WordNetLemmatizer()\n",
    "    sentences = news.split(\".\")\n",
    "    return \" \".join([l.lemmatize(word.lower()) for sentence in sentences for word in sentence.split() \\\n",
    "                     if word not in stopwords if word.isalpha() if len(word)> 2 \\\n",
    "                     if word.lower() not in [\"said\",\"the\",\"first\",\"also\",\"would\",\"one\",\"two\",\"they\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = logistic_model.predict(df.text)\n",
    "\n",
    "s = svc_model.predict(df.text)\n",
    "\n",
    "k = knn_model.predict(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = []\n",
    "for i in s+l+k:\n",
    "    if i > 1.5:\n",
    "        e.append(1)\n",
    "    else:\n",
    "        e.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['log_labels'] = l\n",
    "\n",
    "df['svc_labels'] = s\n",
    "\n",
    "df['knn_labels'] = k\n",
    "\n",
    "df['ens_labels'] = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1004\n",
       "1      46\n",
       "Name: log_labels, dtype: int64"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.log_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    963\n",
       "1     87\n",
       "Name: svc_labels, dtype: int64"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.svc_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    934\n",
       "1    116\n",
       "Name: knn_labels, dtype: int64"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.knn_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    988\n",
       "1     62\n",
       "Name: ens_labels, dtype: int64"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ens_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([all_df,df[['svc_labels','ens_labels']]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('../data/fatih_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
