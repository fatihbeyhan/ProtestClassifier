{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting url list to feed into extraction\n",
    "links = pd.DataFrame(pd.read_csv('data/intern_train.csv'))\n",
    "links_list = list(links.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_links = pd.DataFrame(pd.read_csv(\"data/intern_test.csv\"))\n",
    "test_links_list = list(test_links.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196    1\n",
       "197    0\n",
       "198    0\n",
       "199    0\n",
       "200    0\n",
       "201    0\n",
       "202    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_links.label[-7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newspaper3k Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import fulltext\n",
    "\n",
    "def get_text(url):\n",
    "    \n",
    "    # getting section and location parts (if it exists) from links \n",
    "    meta = []\n",
    "    for part in url.split('/'):\n",
    "        \n",
    "        if part.startswith('tp-'):\n",
    "            meta.append(part[3:])\n",
    "        \n",
    "    section = \"None\"\n",
    "    location = \"None\"\n",
    "    \n",
    "    if len(meta) == 2:\n",
    "        section = meta[0]\n",
    "        location = meta[1]\n",
    "    elif len(meta) == 1:\n",
    "        section = meta[0]  \n",
    "    elif len(meta) == 0:\n",
    "        pass\n",
    "    \n",
    "    # getting the htmls\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    # extract the headline\n",
    "    headline = soup.find_all('h1')[0].text.strip()\n",
    "    \n",
    "    # get the text\n",
    "    text = fulltext(html).replace('\\n',' ').replace('  ',' ')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # clean the staff reporter part. usually its the beginning of the news.\n",
    "    if text.startswith(\"Staff Reporter\"):\n",
    "        text = text[text.index(\":\")+2:]\n",
    "    \n",
    "    \n",
    "    return url,section,location,headline,text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documents(link_df):\n",
    "    # this function will take the list of the urls  and extract one by one and save it into a list which will be a \n",
    "         # dataframe later on. and saving it as .csv to use it. \n",
    "        \n",
    "    l_l = list(link_df.url)\n",
    "    results = []\n",
    "    \n",
    "    for url in l_l:\n",
    "        idx =l_l.index(url)\n",
    "        label = int(list(link_df.label)[idx:idx+1][0])\n",
    "\n",
    "        r = requests.get(url)\n",
    "        \n",
    "        \n",
    "        url,section,location,headline,text=get_text(url)\n",
    "        \n",
    "        results.append([url,section,location,headline,text,label])\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test = create_documents(test_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(res_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"data/extracted_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = create_documents(links_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(res).to_csv(\"data/extracted_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
